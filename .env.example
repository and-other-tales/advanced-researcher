# .env.example - Advanced Researcher Environment Configuration Template
# Copy this file to .env and fill in your values

###################
# Basic Configuration
###################

# Server configuration
HOST=127.0.0.1              # Host to bind the server to (use 0.0.0.0 for all interfaces)
PORT=8080                   # Port to run the server on
LOG_LEVEL=info              # Log level (debug, info, warning, error, critical)
RELOAD=false                # Enable auto-reload for development (set to "true" to enable)

# Application mode
USE_LOCAL=true              # Use local mode with simplified functionality (no external dependencies)
DEBUG=false                 # Enable debug mode (set to "true" to enable)

# Data storage
DATA_MOUNT_PATH=./data      # Path for persistent data storage

###################
# LLM API Keys
###################
# You must set at least one of the following API keys or enable Ollama for local models

# OpenAI API Key (used for embeddings and chat models)
OPENAI_API_KEY=sk-your-openai-key
OPENAI_ORG_ID=              # Optional: Your OpenAI organization ID

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# Google API Key (for Gemini models)
GOOGLE_API_KEY=your-google-api-key

# Fireworks API Key (for Fireworks models)
FIREWORKS_API_KEY=your-fireworks-key

# Cohere API Key (for Cohere models)
COHERE_API_KEY=your-cohere-key

# LangSmith configuration (for tracking and evaluation)
LANGSMITH_API_KEY=ls-your-langsmith-key
LANGSMITH_TRACING=false     # Set to "true" to enable LangSmith tracing
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_PROJECT=advanced-researcher

###################
# Local Model Configuration
###################

# Ollama Configuration (for local models)
USE_OLLAMA=false            # Set to "true" to use Ollama for local models
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2         # Default model to use with Ollama

###################
# Search API Keys
###################

# Tavily API Key (for web search in auto-learning)
TAVILY_API_KEY=tvly-your-tavily-key

# Perplexity API Key (alternative search provider for auto-learning)
PERPLEXITY_API_KEY=pplx-your-perplexity-key

# Serper API Key (another search provider option)
SERPER_API_KEY=your-serper-key

###################
# Vector Database Configuration
###################

# Vector Store Type (options: chroma, weaviate)
VECTOR_STORE=chroma

# Weaviate Configuration (for cloud deployment)
WEAVIATE_URL=https://your-weaviate-cluster.weaviate.network
WEAVIATE_API_KEY=your-weaviate-key
WEAVIATE_DOCS_INDEX_NAME=Advanced_Researcher_Docs
WEAVIATE_EMBEDDING_MODEL=OpenAI  # Options: OpenAI, Cohere, HuggingFace, etc.

# Chroma Configuration (for local deployment)
CHROMA_HOST=localhost       # Only needed for client/server mode
CHROMA_PORT=8000            # Only needed for client/server mode
COLLECTION_NAME=advanced-researcher
CHROMA_EMBEDDING_MODEL=OpenAI  # Options: OpenAI, AllMiniLML6V2, etc.

###################
# Database Configuration
###################

# Record Manager Database (complete URL for PostgreSQL)
RECORD_MANAGER_DB_URL=postgresql://postgres:mysecretpassword@localhost:5432/advanced-researcher

# Individual PostgreSQL Settings (used if RECORD_MANAGER_DB_URL is not provided)
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_USERNAME=postgres
DATABASE_PASSWORD=mysecretpassword
DATABASE_NAME=advanced-researcher

###################
# Document Ingestion Settings
###################

# Document processing
CHUNK_SIZE=1000             # Size of text chunks for embeddings
CHUNK_OVERLAP=200           # Overlap between chunks
FORCE_UPDATE=false          # Force re-ingestion of documents (set to "true" to force)

###################
# Advanced Settings
###################

# Frontend URL (when running frontend separately)
FRONTEND_URL=http://localhost:3000

# CORS settings
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# Caching
ENABLE_CACHE=true           # Enable response caching
CACHE_TTL=3600              # Cache time-to-live in seconds

# Security
JWT_SECRET=                 # Secret for JWT tokens (generate a random string)
ENABLE_AUTH=false           # Enable authentication (set to "true" to enable)

# Deep research configuration
MAX_RESEARCH_DEPTH=3        # Maximum depth for deep research queries
RESEARCH_MODEL=gpt-4        # Model to use for deep research (depends on available API keys)

# Auto-learning configuration
AUTO_LEARN_ENABLED=false    # Enable auto-learning features
AUTO_LEARN_INTERVAL=86400   # Auto-learning interval in seconds (default: 24 hours)

# Functionality flags
ENABLE_DEEP_RESEARCH=true   # Enable deep research features
ENABLE_DYNAMIC_INGEST=true  # Enable dynamic document ingestion
ENABLE_AUTO_LEARN=false     # Enable auto-learning from queries